{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules for building the autoencoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import writefile_run\n",
    "models_file = 'modules.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize']=18,7\n",
    "rcParams['font.size']=15\n",
    "rcParams['axes.grid']=True\n",
    "\n",
    "style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lines_curves_dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a dataset to test modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batches_per_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = LinesCurvesDataset(imgs_per_epoch=batch_size*batches_per_epoch, \n",
    "                          nlines_range=(1, 2), \n",
    "                          ncurves_range=(0, 2), \n",
    "                          nellipses_range=(0, 2), \n",
    "                          x_range=(0, 64), \n",
    "                          y_range=(0, 64), \n",
    "                          dilation_size_range=(2, 5), \n",
    "                          img_size=(64, 64), \n",
    "                          blur_sigma=0.5, \n",
    "                          device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "loader = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa06699358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_inp = dset[0]\n",
    "print(sample_inp.shape)\n",
    "axis('off')\n",
    "imshow(sample_inp.cpu().numpy().transpose([1,2,0]).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block of convs with a residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"One block of convolutions with a residual connection\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert kernel_size%2==1, \"kernel_size should be odd number\"\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding = kernel_size//2)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding = kernel_size//2)\n",
    "        \n",
    "        self.bn1_1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn1_2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.bn2_1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2_2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "            self.res_bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.bn1_1(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1_2(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        out = self.bn2_1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2_2(out)\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            residual = self.res_conv(residual)\n",
    "            residual = self.res_bn(residual)\n",
    "        \n",
    "        out = nn.ReLU()(out+residual)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "torch.Size([32, 32, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test = nn.Sequential(\n",
    "    ConvBlock(1, 16),\n",
    "    ConvBlock(16, 32),\n",
    ").to(DEVICE)\n",
    "\n",
    "inp = next(loader)\n",
    "print(inp.shape)\n",
    "out = test(next(loader))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block of deconvs with a residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    \"\"\"One block of transposed convolutions with a residual connection\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert kernel_size%2==1, \"kernel_size should be odd number\"\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, padding = kernel_size//2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(out_channels, out_channels, kernel_size, padding = kernel_size//2)\n",
    "        \n",
    "        self.bn1_1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn1_2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.bn2_1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2_2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            self.res_conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=1)\n",
    "            self.res_bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.bn1_1(x)\n",
    "        \n",
    "        out = self.deconv1(x)\n",
    "        out = self.bn1_2(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        out = self.bn2_1(out)\n",
    "        out = self.deconv2(out)\n",
    "        out = self.bn2_2(out)\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            residual = self.res_conv(residual)\n",
    "            residual = self.res_bn(residual)\n",
    "        \n",
    "        out = nn.ReLU()(out+residual)\n",
    "           \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "torch.Size([32, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test = nn.Sequential(\n",
    "    DeconvBlock(1, 8),\n",
    "    DeconvBlock(8, 16),\n",
    ").to(DEVICE)\n",
    "\n",
    "inp = next(loader)\n",
    "print(inp.shape)\n",
    "out = test(next(loader))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A set of cascaded blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class BlockSet(nn.Module):\n",
    "    \"\"\"Cascades a set of given blocks. The first block maps in_channels to \n",
    "    out_channels, and remaining blocks map out_channels to out_channels.\"\"\"\n",
    "    def __init__(self, block, in_channels, out_channels, block_count, kernel_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        block1 = block(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        blocks = [block(out_channels, out_channels, kernel_size=kernel_size) for _ in range(block_count-1)]\n",
    "        \n",
    "        self.blocks = nn.Sequential(block1, *blocks)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.blocks(input)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "torch.Size([32, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "convtest = BlockSet(ConvBlock, \n",
    "                in_channels=1, \n",
    "                out_channels=8, \n",
    "                block_count=2).to(DEVICE)\n",
    "\n",
    "inp = next(loader)\n",
    "out = convtest(inp)\n",
    "\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "torch.Size([32, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "deconvtest = BlockSet(DeconvBlock, \n",
    "                in_channels=1, \n",
    "                out_channels=8, \n",
    "                block_count=2).to(DEVICE)\n",
    "\n",
    "inp = next(loader)\n",
    "out = deconvtest(inp)\n",
    "print(inp.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A network of cascaded BlockSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class BlockNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Cascades multiple BlockSets to form a complete network. One BlockSet is used for each element in\n",
    "    the channel_sequence, and size scaling is done between blocks based on size_sequence. A decrease in\n",
    "    size is done using fractional max pooling, and an increase in size is done by bilinear upsampling.\n",
    "    \n",
    "    A final 1x1 block is added after all the BlockSets.\n",
    "    \"\"\"\n",
    "    def __init__(self, block, channel_sequence, size_sequence, block_count, kernel_size=3, use_block_for_last=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(channel_sequence)==len(size_sequence), \"channel and size sequences should have same length\"\n",
    "        \n",
    "        old_channels, old_size = channel_sequence[0], size_sequence[0]\n",
    "        \n",
    "        layers = []\n",
    "        for channels, size in zip(channel_sequence[1:], size_sequence[1:]):\n",
    "            layers.append(BlockSet(block, \n",
    "                                   in_channels=old_channels,\n",
    "                                   out_channels=channels,\n",
    "                                   block_count=block_count,\n",
    "                                   kernel_size=kernel_size))\n",
    "            if size<old_size:\n",
    "                layers.append(nn.FractionalMaxPool2d(kernel_size=kernel_size, output_size=size))\n",
    "            elif size>old_size:\n",
    "                layers.append(nn.Upsample(size=(size,size), mode='bilinear', align_corners=True))\n",
    "            \n",
    "            old_channels, old_size = channels, size\n",
    "        \n",
    "        if use_block_for_last:\n",
    "            layers.append(block(channels, channels, kernel_size=1))\n",
    "        else:\n",
    "            layers.append(nn.Conv2d(channels, channels, kernel_size=1))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "                \n",
    "            \n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.layers(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3620674])\n"
     ]
    }
   ],
   "source": [
    "encodertest = BlockNet(ConvBlock, \n",
    "                   channel_sequence=[1,64,64,128,128], \n",
    "                   size_sequence=[64,32,16,8,1], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3).to(DEVICE)\n",
    "# print(encoder)\n",
    "print(nn.utils.parameters_to_vector(encodertest.parameters()).shape)\n",
    "\n",
    "# inp = next(loader)\n",
    "# encoded = encodertest(inp)\n",
    "# print(inp.shape)\n",
    "# print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3380038])\n"
     ]
    }
   ],
   "source": [
    "decodertest = BlockNet(DeconvBlock, \n",
    "                   channel_sequence=[128,128,128,64,1], \n",
    "                   size_sequence=[1,8,16,32,64], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3).to(DEVICE)\n",
    "# print(encoder)\n",
    "print(nn.utils.parameters_to_vector(decodertest.parameters()).shape)\n",
    "\n",
    "# out = decodertest(encoded)\n",
    "# print(encoded.shape)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Combines an encoder and decoder into an autoencoder\n",
    "    Can supply `return_embedding` as true to get back the embedding as well\"\"\"\n",
    "    def __init__(self, encoder, decoder, output_activation=nn.LeakyReLU()):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.out_act = output_activation\n",
    "        \n",
    "    def forward(self, input, return_embedding=False):\n",
    "        embedding = self.encoder(input)\n",
    "        output = self.out_act(self.decoder(embedding))\n",
    "        \n",
    "        if return_embedding:\n",
    "            return output, embedding\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class NormalizeModule(nn.Module):\n",
    "    \"\"\"Returns (input-mean)/std\"\"\"\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return (input-self.mean)/self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coord Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class CoordConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels+2, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        h = input.shape[2]\n",
    "        w = input.shape[3]\n",
    "        \n",
    "#         print(input.shape)\n",
    "        \n",
    "        i = np.linspace(-1,1,h)\n",
    "        j = np.linspace(-1,1,w)\n",
    "        \n",
    "        ii,jj = np.meshgrid(i,j)\n",
    "        \n",
    "       \n",
    "        ii = torch.tensor(ii, dtype=input.dtype).to(input.device).repeat((input.shape[0],1,1,1))\n",
    "        jj = torch.tensor(jj, dtype=input.dtype).to(input.device).repeat((input.shape[0],1,1,1))\n",
    "        \n",
    "#         print(ii.device,jj)\n",
    "        \n",
    "        inp = torch.cat([input, ii, jj], dim=1)\n",
    "        \n",
    "        out = self.conv(inp)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 62, 62]),\n",
       " tensor([[[[ 0.1873,  0.1699,  0.1525,  ..., -0.8383, -0.8557, -0.8731],\n",
       "           [ 0.1984,  0.1810,  0.1636,  ..., -0.8272, -0.8445, -0.8619],\n",
       "           [ 0.2095,  0.1922,  0.1748,  ..., -0.8160, -0.8334, -0.8508],\n",
       "           ...,\n",
       "           [ 0.8442,  0.8269,  0.8095,  ..., -0.1813, -0.1987, -0.2161],\n",
       "           [ 0.8554,  0.8380,  0.8206,  ..., -0.1702, -0.1876, -0.2050],\n",
       "           [ 0.8665,  0.8491,  0.8317,  ..., -0.1591, -0.1764, -0.1938]],\n",
       " \n",
       "          [[-0.6564, -0.6558, -0.6553,  ..., -0.6243, -0.6238, -0.6232],\n",
       "           [-0.6397, -0.6392, -0.6386,  ..., -0.6077, -0.6071, -0.6066],\n",
       "           [-0.6231, -0.6225, -0.6220,  ..., -0.5910, -0.5905, -0.5899],\n",
       "           ...,\n",
       "           [ 0.3255,  0.3261,  0.3266,  ...,  0.3576,  0.3582,  0.3587],\n",
       "           [ 0.3422,  0.3427,  0.3433,  ...,  0.3743,  0.3748,  0.3753],\n",
       "           [ 0.3588,  0.3594,  0.3599,  ...,  0.3909,  0.3914,  0.3920]],\n",
       " \n",
       "          [[-0.3113, -0.3079, -0.3045,  ..., -0.1109, -0.1075, -0.1041],\n",
       "           [-0.3044, -0.3010, -0.2976,  ..., -0.1040, -0.1006, -0.0972],\n",
       "           [-0.2975, -0.2941, -0.2907,  ..., -0.0971, -0.0937, -0.0903],\n",
       "           ...,\n",
       "           [ 0.0971,  0.1005,  0.1039,  ...,  0.2976,  0.3010,  0.3044],\n",
       "           [ 0.1041,  0.1075,  0.1109,  ...,  0.3045,  0.3079,  0.3113],\n",
       "           [ 0.1110,  0.1144,  0.1178,  ...,  0.3114,  0.3148,  0.3182]],\n",
       " \n",
       "          [[-0.0527, -0.0523, -0.0518,  ..., -0.0268, -0.0263, -0.0259],\n",
       "           [-0.0524, -0.0519, -0.0515,  ..., -0.0264, -0.0259, -0.0255],\n",
       "           [-0.0520, -0.0515, -0.0511,  ..., -0.0260, -0.0256, -0.0251],\n",
       "           ...,\n",
       "           [-0.0311, -0.0307, -0.0302,  ..., -0.0051, -0.0047, -0.0043],\n",
       "           [-0.0307, -0.0303, -0.0299,  ..., -0.0048, -0.0043, -0.0039],\n",
       "           [-0.0304, -0.0299, -0.0295,  ..., -0.0044, -0.0040, -0.0035]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = CoordConv(1, 4).to(DEVICE)\n",
    "\n",
    "testin = dset[0].unsqueeze(0)\n",
    "out = cc(testin)\n",
    "out.shape, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block of coord convs with a residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "class CoordConvBlock(nn.Module):\n",
    "    \"\"\"One block of convolutions with a residual connection. Convolutions are 'CoordConvs'.\n",
    "    They add coordinate meshgrids to input channels.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert kernel_size%2==1, \"kernel_size should be odd number\"\n",
    "        \n",
    "        self.cconv1 = CoordConv(in_channels, out_channels, kernel_size, padding = kernel_size//2)\n",
    "        self.cconv2 = CoordConv(out_channels, out_channels, kernel_size, padding = kernel_size//2)\n",
    "        \n",
    "        self.bn1_1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn1_2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.bn2_1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2_2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            self.res_cconv = CoordConv(in_channels, out_channels, kernel_size=1)\n",
    "            self.res_bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.bn1_1(x)\n",
    "        \n",
    "        out = self.cconv1(x)\n",
    "        out = self.bn1_2(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        out = self.bn2_1(out)\n",
    "        out = self.cconv2(out)\n",
    "        out = self.bn2_2(out)\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            residual = self.res_cconv(residual)\n",
    "            residual = self.res_bn(residual)\n",
    "        \n",
    "        out = nn.ReLU()(out+residual)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "torch.Size([32, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test = nn.Sequential(\n",
    "    CoordConvBlock(1, 8),\n",
    "    CoordConvBlock(8, 16),\n",
    ").to(DEVICE)\n",
    "\n",
    "inp = next(loader)\n",
    "print(inp.shape)\n",
    "out = test(next(loader))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_py36]",
   "language": "python",
   "name": "conda-env-pytorch_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
