{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import writefile_run\n",
    "models_file = 'autoenc_models.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "def conv_conv128(DEVICE=torch.device('cpu')):\n",
    "    \"\"\"Conv-Conv architecture with latent dim of 128. Approx\n",
    "    3.3M params each in encoder and decoder. Leaky ReLU activation.\n",
    "    \n",
    "    Returns encoder, decoder and autoencoder.\n",
    "    Returned decoder includes output activation.\n",
    "    \"\"\"\n",
    "    encoder = BlockNet(ConvBlock, \n",
    "                   channel_sequence=[1,64,64,128,128], \n",
    "                   size_sequence=[64,32,16,8,1], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3,\n",
    "                   use_block_for_last=True).to(DEVICE)\n",
    "\n",
    "    encp = nn.utils.parameters_to_vector(encoder.parameters()).shape[0]\n",
    "    print(f\"Encoder has {encp} params\")\n",
    "    \n",
    "    decoder = BlockNet(ConvBlock, \n",
    "                   channel_sequence=[128,128,128,64,1], \n",
    "                   size_sequence=[1,8,16,32,64], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3,\n",
    "                   use_block_for_last=True).to(DEVICE)\n",
    "\n",
    "    decp = nn.utils.parameters_to_vector(decoder.parameters()).shape[0]\n",
    "    print(f\"Decoder has {decp} params\")\n",
    "    \n",
    "    autoencoder = nn.Sequential(encoder, decoder, nn.LeakyReLU()).to(DEVICE)\n",
    "    \n",
    "    return encoder, nn.Sequential(decoder, nn.LeakyReLU()), autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "def coordconv_conv128(DEVICE=torch.device('cpu')):\n",
    "    \"\"\"CoordConv-CoordConv architecture with latent dim of 128. Approx\n",
    "    3.3M params each in encoder and decoder. Leaky ReLU activation.\n",
    "    \n",
    "    Input is normalized to [-1,1] as (input-0.5)/0.5\n",
    "    \n",
    "    Returns encoder, decoder and autoencoder.\n",
    "    Returned decoder includes output activation.\n",
    "    \"\"\"\n",
    "    encoder = nn.Sequential(\n",
    "        NormalizeModule(0.5,0.5),\n",
    "        BlockNet(CoordConvBlock, \n",
    "                       channel_sequence=[1,64,64,128,128], \n",
    "                       size_sequence=[64,32,16,8,1], \n",
    "                       block_count=5,\n",
    "                       kernel_size=3)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    encp = nn.utils.parameters_to_vector(encoder.parameters()).shape[0]\n",
    "    print(f\"Encoder has {encp} params\")\n",
    "    \n",
    "    decoder = BlockNet(CoordConvBlock, \n",
    "                   channel_sequence=[128,128,128,64,1], \n",
    "                   size_sequence=[1,8,16,32,64], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3).to(DEVICE)\n",
    "\n",
    "    decp = nn.utils.parameters_to_vector(decoder.parameters()).shape[0]\n",
    "    print(f\"Decoder has {decp} params\")\n",
    "    \n",
    "    autoencoder = Autoencoder(encoder, decoder, nn.LeakyReLU()).to(DEVICE)\n",
    "    \n",
    "    return encoder, nn.Sequential(decoder, nn.LeakyReLU()), autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "def coordconv_conv64(DEVICE=torch.device('cpu')):\n",
    "    \"\"\"CoordConv-CoordConv architecture with latent dim of 64. Approx\n",
    "    1M params each in encoder and decoder. Leaky ReLU activation.\n",
    "    \n",
    "    Input is normalized to [-1,1] as (input-0.5)/0.5\n",
    "    \n",
    "    Returns encoder, decoder and autoencoder.\n",
    "    Returned decoder includes output activation.\n",
    "    \"\"\"\n",
    "    encoder = nn.Sequential(\n",
    "        NormalizeModule(0.5,0.5),\n",
    "        BlockNet(CoordConvBlock, \n",
    "                       channel_sequence=[1,32,32,64,64], \n",
    "                       size_sequence=[64,32,16,8,1], \n",
    "                       block_count=5,\n",
    "                       kernel_size=3)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    encp = nn.utils.parameters_to_vector(encoder.parameters()).shape[0]\n",
    "    print(f\"Encoder has {encp} params\")\n",
    "    \n",
    "    decoder = BlockNet(CoordConvBlock, \n",
    "                   channel_sequence=[64,64,64,32,1], \n",
    "                   size_sequence=[1,8,16,32,64], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3).to(DEVICE)\n",
    "    \n",
    "    decp = nn.utils.parameters_to_vector(decoder.parameters()).shape[0]\n",
    "    print(f\"Decoder has {decp} params\")\n",
    "    \n",
    "    autoencoder = Autoencoder(encoder, decoder, nn.LeakyReLU()).to(DEVICE)\n",
    "    \n",
    "    return encoder, nn.Sequential(decoder, nn.LeakyReLU()), autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $models_file -a\n",
    "\n",
    "\n",
    "def coordconv_conv256(DEVICE=torch.device('cpu')):\n",
    "    \"\"\"CoordConv-CoordConv architecture with latent dim of 256. Approx\n",
    "    8M params each in encoder and decoder. Leaky ReLU activation.\n",
    "    \n",
    "    Input is normalized to [-1,1] as (input-0.5)/0.5\n",
    "    \n",
    "    Returns encoder, decoder and autoencoder.\n",
    "    Returned decoder includes output activation.\n",
    "    \"\"\"\n",
    "    encoder = nn.Sequential(\n",
    "        NormalizeModule(0.5,0.5),\n",
    "        BlockNet(CoordConvBlock, \n",
    "                       channel_sequence=[1,64,64,128,256], \n",
    "                       size_sequence=[64,32,16,8,1], \n",
    "                       block_count=5,\n",
    "                       kernel_size=3)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    encp = nn.utils.parameters_to_vector(encoder.parameters()).shape[0]\n",
    "    print(f\"Encoder has {encp} params\")\n",
    "    \n",
    "    decoder = BlockNet(CoordConvBlock, \n",
    "                   channel_sequence=[256,256,128,64,1], \n",
    "                   size_sequence=[1,8,16,32,64], \n",
    "                   block_count=5,\n",
    "                   kernel_size=3).to(DEVICE)\n",
    "\n",
    "    decp = nn.utils.parameters_to_vector(decoder.parameters()).shape[0]\n",
    "    print(f\"Decoder has {decp} params\")\n",
    "    \n",
    "    autoencoder = Autoencoder(encoder, decoder, nn.LeakyReLU()).to(DEVICE)\n",
    "    \n",
    "    return encoder, nn.Sequential(decoder, nn.LeakyReLU()), autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_py36]",
   "language": "python",
   "name": "conda-env-pytorch_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
